---
title: "Rapport de laboratoire 2"
subtitle: "MTH8408"
author:
  - name: Votre nom
    email: votre.adresse@polymtl.ca
    affiliation:
      - name: Polytechnique Montréal
format:
  pdf:
    keep-tex: false
    documentclass: article
    include-in-header:
      - text: |
            \usepackage{eulervm}
            \usepackage{xspace}
            \usepackage[francais]{babel}
    geometry:
      - margin=1in
    papersize: letter
    colorlinks: true
    urlcolor: blue
engine: julia
---

```{julia}
#| output: false
using Pkg
Pkg.activate("labo2_env")
using LinearAlgebra
using Printf
```

# Contexte

Dans ce laboratoire, on demande d'implémenter deux méthodes itératives pour résoudre
$$
  \min_x \ g^T x + \tfrac{1}{2} x^T H x
$$ {#eq-qp}
où $g \in \mathbb{R}^n$ et $H$ est une matrice $n \times n$ symétrique et définie positive.

# Question 1

En cours, nous avons vu la méthode de la plus forte pente avec recherche linéaire exacte pour résoudre ([-@eq-qp]).

Dans cette question, on demande d'implémenter et de tester cette méthode sur divers objectifs quadratiques convexes.

Votre implémentation doit avoir les caractéristiques suivantes :

1. un critère d'arrêt absolu et relatif sur le gradient de l'objectif ;
2. un critère d'arrêt portant sur le nombre d'itérations (le nombre maximum d'itérations devrait dépendre du nombre de variables $n$ du problème) ;
2. toujours démarrer de l'approximation initiale $0$ ;
3. allouer un minimum en utilisant les opérations vectorisées (`.=`, `.+`, `.+=`, etc.) autant que possible ;
4. calculer *un seul* produit entre $H$ et un vecteur par itération ;
5. n'utiliser $H$ qu'à travers des produits avec un vecteur (ne pas accéder aux éléments de $H$ ou indexer dans $H$) ;
5. ne dépendre que de `LinearAlgebra`.
6. votre fonction principale doit être documentée---reportez-vous à [https://docs.julialang.org/en/v1/manual/documentation](https://docs.julialang.org/en/v1/manual/documentation) ;
7. votre fonction doit faire afficher les informations pertinentes à chaque itération sous forme de tableau comme vu en cours.

Tester votre implémentation sur les problèmes quadratiques de la section *Problèmes test* ci-dessous.

```{julia}
"""
steepest_qp(g, H, eps_a=1.0e-5, eps_r=1.0e-5)

Résout un problème quadratique non contraint à l'aide de la méthode 
du **gradient à pas optimal** (Steepest Descent),
où `H` est une matrice symétrique définie positive.

# Arguments

- `g::Vector{Float64}` : le gradient du problème quadratique (terme linéaire),
- `H::Matrix{Float64}` : la matrice hessienne symétrique définie positive,
- `eps_a::Float64` : tolérance **absolue** pour l'arrêt (défaut = 1e-5),
- `eps_r::Float64` : tolérance **relative** (défaut = 1e-5).

# Retour

- `x::Vector{Float64}` : vecteur solution approximative minimisant
 la fonction quadratique,
- `k::Int` : nombre d'itérations effectuées.

# Affichage à chaque itération :
- `||résidu||` : norme du gradient actuel (condition d’arrêt),
- `||erreur||` : distance à la solution exacte,
- `quadratic function` : valeur de la fonction quadratique.


"""
function steepest_qp(g, H, eps_a=1.0e-5, eps_r=1.0e-5)

    # Taille du problème
    n = length(g) 
    # Initialisation de la derection
    p = -g
    beta = p'*p
    nrmg = copy(sqrt(beta))
    k=0

    # Point initial
    x=zeros(n)
    # Solution exact
    xstart = -H\g
    nrmx = norm(xstart)
    # Initialisationd de l'objectif
    quadra = 0
    println("Iter\t||résidu relatif ||\t||erreur relatif||\t quadratic function")
    while sqrt(beta) > eps_a + eps_r*nrmg  && k < n

        k+=1 
        q = H*p
        alpha = beta/(p'*q)
        # Mise à jour des itérés et des directions
        x .+= alpha * p
        p .-= alpha * q 
        beta = p'*p
        nrmerror = norm(xstart - x)
        # Mise à jour de la fonction objective
        quadra -= 0.5*alpha*beta

        println(@sprintf("%d\t\t\t%.3e\t\t\t\t%.3e\t\t\t\t%.3e", 
        k, sqrt(beta)/nrmg, nrmerror/nrmx, quadra))
    end
    println("Le nombre de multiplication par H     :", k)
    return x, k
    
end
```

# Question 2

Dans cette question, on demande d'implémenter la méthode BFGS pour résoudre le problème quadratique convexe ([-@eq-qp]).

Votre implémentation doit avoir les mêmes caractéristiques qu'à la question 1.

Ici, on cherche notamment à valider le résultat disant que la méthode se termine en au plus $n$ itérations (en arithmétique exacte) et reconstruit $H$, c'est-à-dire que $B_k = H$ à la convergence.

Tester votre implémentation sur les problèmes quadratiques de la section *Problèmes test* ci-dessous.

```{julia}
"""
bfgs_qp(g, H, eps_a=1.0e-5, eps_r=1.0e-5)

Résout un problème quadratique en utilisant la méthode **BFGS**.
# Arguments

- `g::Vector{Float64}` : le vecteur gradient (terme linéaire de la fonction quadratique),
- `H::Matrix{Float64}` : la matrice de Hessien (symétrique définie positive),
- `eps_a::Float64` : tolérance **absolue** sur la norme du gradient (défaut = 1e-5),
- `eps_r::Float64` : tolérance **relative** (défaut = 1e-5).

# Retour

- `x::Vector{Float64}` : solution approchée du problème,
- `k::Int` : nombre d’itérations effectuées.
"""

function bfgs_qp(g, H, eps_a=1.0e-5, eps_r=1.0e-5)

    n = length(g)
    x = zeros(n)
    x_new = copy(x)
    In = Matrix(I,n,n)  
    Hess = In      
    r = copy(g)
    r_new = copy(r)
    p = -r
    beta = p'*r
    nrmg = norm(r)
    nrm  = copy(nrmg)
    k = 0
    xstart = -H\g
    nrmx = norm(xstart)
    quadra = 0
    println("Iter\t\t||résidu relatif||\t||erreur relatif||\t quadratic function")
    while nrm > eps_a + eps_r.*nrmg && k < n

      k += 1
      q = H*p
      alpha = -beta/(p'*q)

      # Mise à jour des itérés et des résidus
      x_new .+= alpha.* p
      r_new .+= alpha.* q

      # Aprroximation de l'inverse du hessien 
      s = x_new - x
      y = r_new - r

      rho = 1/(y'*s)
      V = In - (rho.*s)*y'
      Hess = V*Hess*V'+(rho.*s)*s' 

      # Direction de descente
      p = -(Hess*r)

      x = copy(x_new)
      r = copy(r_new)
      
      beta = p'*r

      # Norme du gradient
      nrm = norm(r)
      # Mise à jour de la fonction objective
      quadra += 0.5*alpha*beta
      # Norme de l'erreur
      nrmerror = norm(xstart - x)
      println(@sprintf("%d\t\t\t%.3e\t\t\t\t%.3e\t\t\t\t%.3e", 
    k, nrm/nrmg, nrmerror/nrmx, quadra))

    end
    println("Le nombre de multiplication par H   :", k)
    return x, k
    
end
```

# Résultats numériques

## Problèmes test

Votre premier problème test sera généré aléatoirement avec $n = 10$.

```{julia}
n = 10
g_rand  = ones(n)
A       = rand(n, n)
H_rand  = Matrix(I, n, n) + A*A'
x, iter = bfgs_qp(g_rand, H_rand)
```

Utiliser ensuite les problèmes quadratiques convexes de la collection Maros et Meszaros.
Vous pouvez y accéder à l'aide de l'extrait de code suivant :
```{julia}
#| output: false
Pkg.add("QPSReader")  # collection + outils pour lire les problèmes

using QPSReader
using Logging
using SparseArrays

function get_gH(name, reg=0)
  mm_path = fetch_mm()  # chemin vers les problèmes sur votre disque
  qpdata = with_logger(Logging.NullLogger()) do
    readqps(joinpath(mm_path, name))
  end
  n = qpdata.nvar
  g = qpdata.c
  H = Symmetric(sparse(qpdata.qrows, qpdata.qcols, qpdata.qvals, n, n) + reg * I, :L)
  return g, H
end
```

Les noms des problèmes sont listés sur [https://bitbucket.org/optrove/maros-meszaros/src/master/](https://bitbucket.org/optrove/maros-meszaros/src/master/).

Leurs dimensions sont donnés dans le tableau sur la page [https://www.doc.ic.ac.uk/~im/00README.QP](https://www.doc.ic.ac.uk/%7Eim/00README.QP) (avec des noms qui ne correspondent pas tout à fait ; les noms corrects sont ceux de la page Bitbucket).

NB : ces problèmes ont des contraintes, mais dans ce laboratoire, on les ignore.

Choisissez 3 problèmes :

* un avec $n \approx 10$ ;
* un avec $n \approx 50$ ;
* un avec $n \approx 100$.

```{julia}
g100, H100 = get_gH("CVXQP1_S.SIF")
```

Attention :

* il se peut que $g = 0$---dans ce cas, changez $g$ en `ones(n)` ;
* il se peut que $H$ soit seulement semi-définie positive et pas définie positive---dans ce cas, ajoutez-lui un petit multiple de l'identité via, par exemple,

```julia
g, H = get_gH(name, 1.0e-3)
```

```{julia}
g10, H10 = get_gH("ksip.SIF", 1.0e-3)
println(g10)
g50, H50 = get_gH("qafiro.SIF", 1.0e-3)
println(g50)
g50 = ones(length(g50))
g100, H100 = get_gH("qadlittl.SIF", 1.0e-3)
println(g100)
```

## Validation de la méthode de la plus forte pente

```{julia}
x, k = steepest_qp(g10, H10)
x, k = steepest_qp(g50, H50)
x, k = steepest_qp(g100, H100)
```


## Validation de la méthode BFGS

```{julia}
x, k = bfgs_qp(g10, H10)
x, k = bfgs_qp(g50, H50)
x, k = bfgs_qp(g100, H100)
```
